# 深度学习-54:通用人工智能,Singularity‎

## OpenAI组织

OpenAI的使命是确保通用人工智能 (Artificial General Intelligence, AGI)，即一种高度自主且在大多数具有经济价值的工作上超越人类的系统，将为全人类带来福祉。我们不仅希望直接建造出安全的、符合共同利益的通用人工智能，而且愿意帮助其它研究机构共同建造出这样的通用人工智能以达成我们的使命。为了达到这个目标，我们制订了如下原则：

## 通用AI的特征

通用人工智能应包括以下三大特点或者说难点：

- 通用任务：既能唱歌绘画、又能下棋写诗，最重要的是要尽量减少对 领域知识 （Domain Knowledge）的依赖。
- 学习能力：无论是通过逻辑推理的 演绎法 来学习，或者是基于经验和记忆的 归纳法 来学习，都要通过学习来提高处理通用任务的适用性。
- 自省能力：也可以说是关于学习的学习，即 元认知 ，通过自省来纠偏行为。就像泰勒展开一样，我们大可以用低阶导数来逼近函数值，而无需考虑元认知的元认知这类高阶导数。

## 人工智能（AI）与通用人工智能（AGI）

“人工智能（AI）”没有公认的严格定义，尽管简而言之，这项研究是试图“让计算机像人脑一样工作”。尽管听上去似乎直截了当，这种看法实际上要求AI在某些方面与人类智能相似（甚至相同）。由于计算机既非生物有机体，也不可能过和人类一模一样的生活，故而期望人工智能与人类智能在所有方面都完全一样显然是不切实际的。但这是个自明的“潜假设”，很少被明确提及。其结果是当人们关注人类智能的不同方面时，提出和遵从的AI范式彼此迥异，其目标、需求、假设、路径和应用均大相径庭。

在相关讨论中，至少存在三种不同见解：

- 认为“AI”应该行为表现与人完全一致。
- 认为“AI”应该能够解决某些过去只有人脑才能解决的问题。
- 认为“AI”应该具有与人相同的认知功能。

在后面的讨论中，它们将分别被称为AI-1、AI-2和AI-3。就AI-1而言，最广为人知的形式莫过于一个能够通过图灵测试的计算机系统。由于通俗易懂，这种AI经常出现在科幻小说和电影中。在公众看来，这就是“AI”的含义。但事实上，这基本上不是人工智能领域的研究目标。

在AI研究的初期（上个世纪中叶），绝大多数研究者的确都试图创建在各方面均可与人类心智相媲美（尽管未必完全相同）的“思维机器”。然而，对这一目标的所有直接尝试均宣告失败。于是，主流AI研究者将“AI”重新诠释为AI-2，即在某一特定应用或认知功能上达到人类水平。常规AI教科书中几乎所有的内容都成为了AI-2的脚注，就连新近增补的深入学习和其他机器学习算法也无出其右。

尽管AI-2取得了令人瞩目的成就，业界内外的许多人仍然觉得这种系统其实更接近传统计算而非一般意义的智能。这也正是十几年前需要引入“通用人工智能（AGI）”这个新词的原因。尽管这类研究项目实际上从AI之初便一直存续至今，但是当主流AI已经在这个招牌下从事不同的经营活动之后，给这个目标取个新名字就成为必要的了。AGI将“智能”视为一种一般能力，而主流AI则将其视作多种具体能力的松散集合。因此，AGI更接近于前述AI-3。

许多人用“强AI”称呼AI-1和AI-3（以及AGI），而用“弱AI”指AI-2。虽然这个区分有其直观吸引力，很多AGI研究者通常并不用“强AI”来称呼自己的研究工作。理由一是避免该对语词背后潜藏着的哲学预设（“强AI”和“弱AI”的差别原本就不体现在外部功能上，而是系统是否有“内省”能力），二是AI-2与AI-3的主要区别不在于“能力的强弱”，而在于“适用的范围”。对某一确定性问题而言，专用方案的能力往往强于通用方案。因此，期望AI-2的技术变得“更强大”而最终跃升为AI-3是不现实的，因为二者的设计源自根本不同的出发点。换言之，将现有AI-2技术捆绑整合而成为AI-3系统的想法是不会实现的。

此外，AI-1侧重于系统的外在行为，而AI-3则侧重于其内部功能，但“强AI”这个概念却无法区分AI-1和AI-3。尽管有理由认为“行为表现与人脑完全一致的计算机系统”（AI-1）大约依赖于“与人类心智相同的认知功能”（AI-3），但反过来却未必成立。系统的行为（或其“输出”）不仅取决于内部的处理机制和功能，还依赖于系统的“输入”（可粗略称其为“经验”）。因此，“类人”的认知机制如果被给予“非人”的经验，其行为也不会像人。这就好比在输入值差别很大的情况下，即使两个数学函数几乎等同，但其输出值也可能有着天壤之别。

那么，为何不能给AGI人类的经验呢？原则上，人类感官及感知过程均可能被计算设备模拟到任意精度，但这在实际上却不太可能。以视觉为例：每种光感受器都应具有一定的灵敏度、解析度、反应时等等。人眼如此，其它动物的眼或各种电子感光设备也莫不如此。因此，“让计算机有视觉”和“让计算机有和人类完全一样的视觉”是两个难度相差悬殊的任务。

退一万步讲，即便能够在所有细节上模拟人类的全部感官，也仍然只能得到某人的直接的物理经验，依旧无法获取从人际交流中得到的间接的社会经验。因为社会经验的取得，需要计算机被其他人（或机器）视为人。这已然不是能否实现的技术问题，而是是否需要或值得去做的问题了。

为了便于讨论，假设全体人类社会确实像对待人类一般来对待AGI系统；在这种情况下，AI-1是有可能实现的。然而，这是基于对“智能”高度的人类中心主义的解释，其实它应该被称为“人工的人类智能”。用人类行为来刻画智能会令其他非人智能（如“动物智能”、“群体智能”、“外星智能”等）仅根据定义便成为不可能，仅仅因为它们并不具有类人的输入和输出。

这种人类中心主义的“智能观”总是作为隐含的预设立场而存在，却几乎未被明确地讨论过。一个突出的例子便是将图灵测试作为AI的操作性定义，尽管图灵自己只是将其视为智能或思维的充分条件而非必要条件。图灵本人写道：“难道机器不能进行一些与人不同却可称之为思维的活动？这个反诘很有力，但至少我们可以说，如果能够很好地应对角色扮演任务的机器可以被造出来，我们就不必为这种反诘而烦恼”。这就是说，即使“行为像人”说明有智能，“行为不像人”也未必就是没有智能。

在当前AGI研究中，几乎没有人将目标设定为建立AI-1系统；相反，将他们的工作视为某种AI-3的版本才更适合。他们认为，“思维机器”或“通用智能”不仅和人类心智有可比性，甚至可能在某种抽象意义上完全相同，尽管未必是行为细节的全部等同。就像我们认为鱼和鸟有视觉但却与人类之所见非常不同一样，这种行为差异的存在并不意味着非人系统无法拥有真正的智能。

## “奇点”（Singularity‎）与通用人工智能（AGI）

“奇点”，也被称为“技术奇点”，是另一个既无准确含义也未被广泛接受的概念。尽管常见于一些作品而为公众所熟知，但实际上这并不是一个真正的计算机科学或技术术语。

“AI将导致奇点”这一观点的典型表述可以分解为下列三个结论：

- 系统的智能水平可以表示为一个数值。
- 经由学习或迭代改进，AI能够提升自己的智能水平。
- 当AI的智能水平超越人类，它的整个未来将被我们视作一个单点，因为从那以后这个系统将超出人类的理解范围。

当然，有人也仅使用“奇点”一词来指代“AI达到人类水平”或“计算机比人类更聪明”这个时间节点，而不做其他假设。接下来，我们将聚焦于上述典型表述，因为当它被分析之后，我们对其各种变体的看法也便一望而知了。

AGI将是在原理、机制和功能上与人类智能相似的计算机系统，却不必然非得在内部结构、外部行为或问题解决能力上与人一致。作为另一种智力形式，AGI将具有与人类大致相同的智能水平，既不会过不高也不会过低。对于具体的问题解决能力而言，由于躯体和经验的差别，AGI既可能比人强也可能不如人。

AGI的实现需要新理论、新模型和新技术。当前主流AI基本上延循着智能就是问题解决能力这一思路而发展，所以其发展路线并未朝向AGI，从而也具有与AGI所不同的理论和实践价值。

即使AGI已然实现，也不会导致一个奇点出现，以至于智能计算机系统变得完全无法理解、不可预知和无法控制。相反，AGI的实现意味着智能本质已为人所悉，这将进一步引导人们使用AGI来满足人类的价值和需求。

AGI的研究还处于初期，因此各方高见皆有价值。但正所谓“大川归道，百宝万货”，为了取得一个最低共识有必要澄清基本问题，以便避免驴唇不对马嘴的情况出现。

## 系列文章

- [Gihutb专栏: 机器学习&深度学习(理论/实践)](https://github.com/media-tm/MTOpenML)
- [CSDN专栏: 机器学习理论与实践](https://blog.csdn.net/column/details/27839.html)
- [CSDN专栏: 深度学习理论与实践](https://blog.csdn.net/column/details/27839.html)

## 参考文献

- [1] Ian Goodfellow, Yoshua Bengio. [Deep Learning](http://www.deeplearningbook.org/). MIT Press. 2016.
- [2] 焦李成等. 深度学习、优化与识别. 清华大学出版社. 2017.
- [3] 佩德罗·多明戈斯. 终极算法-机器学习和人工智能如何重塑世界. 中信出版社. 2018.
- [4] 雷.库兹韦尔. 人工智能的未来-揭示人类思维的奥秘.  浙江人民出版社. 2016.
