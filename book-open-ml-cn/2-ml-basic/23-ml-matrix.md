# 矩阵理论

线性代数是数学的一个分支，广泛应用于科学和工程领域。线性代数和矩阵理论是机器学习和人工智能的重要数学基础。有短板的请补课，推荐《The Matrix Cookbook》。线性代数主要涉及矩阵理论，本节围绕矩阵理论展开。

## 1 标量和、向量和张量

**标量**: 一个标量就是一个单独的数字
**向量**: 一个向量就是一列数字。例如  x= [x1,x2,...xn]
**矩阵**:一个矩阵就是一个二维数组 A = [[A11,A12], [A21,A22]]
**张量**: 一个数组中的元素分布于若干坐标的规则网格中，称为张量

## 2 矩阵和矩阵的性质

矩阵乘积具有分配律: A(B+C)=AB+AC
矩阵乘积具有结合律: A(BC)=(AB)C
单位矩阵和逆矩阵
对角矩阵
线性相关

## 3 范数

衡量一个向量的大小，在机器学习中称为范数。范数的定义为:
$$||x||_p = (\sum_{n=1}^N|x_i|^p)^1/p$$
L1
L2 范数称为欧几里得范数

## 4 特征分解

我们通过分解质因数可以发现部分整数的内在性质，同样我们通过矩阵分解可以发现组成矩阵的数字元素的性质。**特征分解**将矩阵分解成一组特征向量和特征值。

## 5 奇异值分解

奇异值分解顾名思义，将矩阵分解为奇异向量和奇异值。通过奇异值分解我们会得到与特征分解相同类型的信息。

## 参考文献

- [1] Ian Goodfellow, Yoshua Bengio. [Deep Learning](http://www.deeplearningbook.org/). MIT Press. 2016.
- [2] 焦李成等. 深度学习、优化与识别. 清华大学出版社. 2017.
- [3] 佩德罗·多明戈斯. 终极算法-机器学习和人工智能如何重塑世界. 中信出版社. 2018.
- [4] 雷.库兹韦尔. 人工智能的未来-揭示人类思维的奥秘.  浙江人民出版社. 2016.
