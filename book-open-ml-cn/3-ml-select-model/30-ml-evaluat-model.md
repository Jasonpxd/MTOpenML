# 特征工程与模型选择

> 一起创作,Come on!!! [简练而全面的开源ML&AI电子书](https://github.com/media-tm/MTOpenML)

## 1 数据预处理

数据预处理包括: 数据清洗、数据格式转换和领域知识收集等。数据清洗的任务是过滤掉不符合要求的数据；不符合要求的数据主要是不完整的数据、错误的数据和重复的数据。过滤掉的数据需要业务部门是否需要重新采集，是否需要修正，是否包含重要隐含特征等？

数据清洗之后的合格数据，需要经过显式数据格式转换，转换成目标系统的数据格式，并存在数据仓库中。另外，和数据相关的领域知识也需要简单收集，数据相关的领域知识有助于数据的特征工程，和机器学习的结果的检验和解释工作。

数据预处理可能占整个机器学习项目的80%，其是一个繁杂的系统工程，数据预处理的工作质量对整个机器学习项目的质量有重大影响。

## 2 数据特征工程

> 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。

特征工程是模型训练的前置条件，特征工程的目的是最大限度地从原始数据中提取特征以供算法和模型使用。特征处理是特征工程的核心部分，sklearn提供了较为完整的特征处理方法，包括数据预处理，特征选择，降维等。

当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。一般可以采用发散度和相关度来选择特征：

- 度量特征的发散度：通过方差计算特征的发散度，优选方差大的特征。
- 度量特征的相关度：计算特征和目标的相关度，优选与目标相关性高的特征。

我们使用sklearn中的feature_selection库来进行特征选择。根据特征选择的形式又可以将特征选择方法分为3种：

- 过滤法(filter), 按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。过滤法工具箱包括:方差选择法、相关系数法、卡方检验和互信息法等。
- 包装法(wrapper), 根据目标函数(通常是预测效果评分)，每次选择若干特征，或者排除若干特征。包装法工具箱包括:递归特征消除法、
- 集成法(embedded), 先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。集成法工具箱包括:基于惩罚项的特征选择法、基于树模型的特征选择法。

对于多特征的数据集，由于特征矩阵过大，机器学习的效果不是很理想。这时，降低特征矩阵维度是非常必要的步骤。降维方法可采用主成分分析法(PCA)和线性判别分析(LDA)。

## 3 实施机器学习算法

按照任务目标的不同可以将机器学习算法分为回归算法、分类算法和聚类算法。实施机器学习算法简单来说就是：选择模型、优化模型和度量模型性能。

### 3.1 选择模型

机器学习算法有回归算法、分类算法和聚类算法。根据数据的特征和领域经验为基础即可选出合适的机器学习方法。

### 3.2 优化模型

模型诊断中至关重要的是判断过拟合、欠拟合，常见的方法是绘制学习曲线，交叉验证。通过增加训练的数据量、降低模型复杂度来降低过拟合的风险，提高特征的数量和质量、增加模型复杂来防止欠拟合。诊断后的模型需要进行进一步调优，调优后的新模型需要重新诊断，这是一个反复迭代不断逼近的过程，需要不断的尝试，进而达到最优的状态。

### 3.3 度量模型性能

通过测试数据，验证模型的有效性，观察误差样本，分析误差产生的原因，往往能使得我们找到提升算法性能的突破点。误差分析主要是分析出误差来源与数据、特征、算法。必要时使用融合方法提升模型性能。

## 4 发布解决方案

工程上是结果导向，模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。

## 相关内容

- [3.0 模型评估与选择](./30-ml-evaluat-model.md)
- [3.1 经验误差与过拟合](./31-ml-loss-overfit.md)
- [3.2 性能度量](./32-ml-performance-measure.md)
- [3.3 偏差与方差](./33-ml-deviation-variance.md)

## 参考文献

- [1] 周志华. 机器学习. 清华大学出版社. 2016.
- [2] [日]杉山将. 图解机器学习. 人民邮电出版社. 2015.
- [3] 佩德罗·多明戈斯. 终极算法-机器学习和人工智能如何重塑世界. 中信出版社. 2018.